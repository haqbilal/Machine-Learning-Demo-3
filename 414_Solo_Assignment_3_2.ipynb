{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBQjOo49-ilX"
      },
      "source": [
        "# Changelog:\n",
        "\n",
        "Last Update: 2022-03-20\n",
        "\n",
        "Changes:\n",
        "\n",
        "1. token_to_index returns `vocab[token]`\n",
        "2. Improve doscstring for `create_vocab`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q84Rhsk6FOWx"
      },
      "source": [
        "# Question 2: Natural Language Processing\n",
        "\n",
        "### Total Points: 46\n",
        "\n",
        "### Background:\n",
        "In this question you will fit a set of models with the goal of predicting which text messages (SMS) are spam and which are not. \n",
        "\n",
        "You will be experimenting with a variety of different embedding algorithms followed by Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_9JVHlrC4sg",
        "outputId": "bae05a2d-928f-407f-8b09-d9d21730e903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.9.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.63.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.21.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.25.11)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!python -m spacy download en_core_web_md\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mbhj24iFMEJ"
      },
      "source": [
        "## Data Loading, Exploratory Data Analysis and Vocabulary Creation:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDe_6kaRCfWs"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from typing import List\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "47ecf0729e0e4254b9e8ee8799046881",
            "096cf2df2a6d4528abeb278a9052a2e3",
            "2a80b85e68ad4282ba783c797609f0b7",
            "f2e46b810c2f418fb03425f4d340a1ff",
            "efe8416bb61f48f2a2ea5a9577eaf9e5",
            "286c0d606def4bef863dce56c054edf3",
            "2e6a5649710f4bf8b2c070f1d3062ff9",
            "90e1adccc17d4be18d4b2acd45781920",
            "6c14746adc894090ab69ed81222578d6",
            "1c0e7c008f8a4c01a2687786c953c987",
            "1349f6db6f404b85bb78e86f5b55bff9"
          ]
        },
        "id": "Z-YrzSxEC2Hq",
        "outputId": "f6503d87-7cc6-4879-d91b-3975adaa4698"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset sms_spam (/root/.cache/huggingface/datasets/sms_spam/plain_text/1.0.0/53f051d3b5f62d99d61792c91acefe4f1577ad3e4c216fb0ad39e30b9f20019c)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47ecf0729e0e4254b9e8ee8799046881",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset(\"sms_spam\")\n",
        "texts = [x[\"sms\"] for x in dataset[\"train\"]]\n",
        "labels = [x[\"label\"] for x in dataset[\"train\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X523_TcvC_4S"
      },
      "outputs": [],
      "source": [
        "X_train, X_m, y_train, y_m = train_test_split(texts, labels, test_size=0.3, random_state=0)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_m, y_m, test_size = 0.5, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-MHbxEmE2Hr"
      },
      "outputs": [],
      "source": [
        "def tokenize(x:str) -> List[str]:\n",
        "  \"\"\"\n",
        "  Takes string as an input and returns a list of tokens. This just splits the string x on whitespace\n",
        "  \"\"\"\n",
        "  return x.lower().split(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWyKRONCVFYD"
      },
      "source": [
        "##[ 5 points ] Q2.a: Determine / Answer the following: \n",
        "\n",
        "*   How many datapoints are in the training set?\n",
        "*   How many total tokens are there in the data?\n",
        "*   What % of training examples are spam?\n",
        "*   What would the accuracy be if for every datapoint we predict it is spam? (explain)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un_LMIlBBZu1"
      },
      "source": [
        "*   2 features in 5574 rows for a total of 11148 datapoints.\n",
        "*   There are 14,856 unique tokens\n",
        "*   Approximately 13.4% of the training exmaples are spam\n",
        "*   The accuracy would be approximately 13.4% because we accurately classify all of these spams and none of the non spam cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS6ufPCtGwQp"
      },
      "source": [
        "##[4 points ] Q2.b Vocabulary and Frequencies  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyKQsSieGzDk"
      },
      "source": [
        "Implement the functions `create_count_dict`, and `create_vocab` below that take as input a dataset (list of untokenized strings - one per datapoint), and an integer representing the desired vocabulary size, and returns the vocabulary as a `dict` whose keys are tokens and whose values are indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACy4z8-oGSEp"
      },
      "outputs": [],
      "source": [
        "def create_count_dict(dataset:List[str]) -> dict:\n",
        "  \"\"\"\n",
        "  Given a dataset, returns a dictionary of token counts with tokens being keys, and counts being values\n",
        "  \"\"\"\n",
        "  count_dict = {}\n",
        "\n",
        "  vectorizer = CountVectorizer()\n",
        "  X = vectorizer.fit_transform(dataset)\n",
        "  lst = vectorizer.get_feature_names_out()\n",
        "  x_arr = X.toarray()\n",
        "\n",
        "  for i in range(len(lst)):\n",
        "    count_dict[lst[i]] = np.sum(x_arr[:, i])\n",
        "\n",
        "  return count_dict\n",
        "\n",
        "def create_vocab(dataset:List[str], vocab_size:int) -> dict:\n",
        "  \"\"\"\n",
        "  Given a dataset, returns a dictionary with tokens as keys and indices as values.\n",
        "\n",
        "  {\"most_common_token\": 0, \"second_most_common_token\": 1, ...}\n",
        "  \"\"\"\n",
        "\n",
        "  # 1. Determine the count of all words\n",
        "  count_dict = create_count_dict(dataset)\n",
        "\n",
        "  # 2. Keep the top <vocab_size> tokens\n",
        "  top = {}\n",
        "  copy = count_dict.copy()\n",
        "  for i in range(vocab_size):\n",
        "      k = max(copy, key=copy.get)\n",
        "      top[k] = i\n",
        "      del copy[k] # delete the key we just took\n",
        "\n",
        "  # 3. Create the token to index dict and fill it with just the top tokens\n",
        "  vocab_to_index_dict = top.copy()\n",
        "  \n",
        "  return vocab_to_index_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWgGXqOtnXaU"
      },
      "outputs": [],
      "source": [
        "# Helper test to at least ensure the constructed vocab is the right size\n",
        "for i in np.random.randint(low = 100, high = 500, size = 5):\n",
        "  assert(len(create_vocab(X_train, vocab_size = i)) == i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CawjqIMXd3X3"
      },
      "outputs": [],
      "source": [
        "# Create and save your vocab\n",
        "student_created_count_dict = create_count_dict(X_train)\n",
        "student_created_vocab = create_vocab(X_train, vocab_size = 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx3Q8FkdrDpJ"
      },
      "source": [
        "##[4 points] Q2.c Token Counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uns15d63rJS1"
      },
      "source": [
        "### Q2.c.a  Is the distribution of token counts below a relatively heavy-tailed distribution?  Would using only the top 30 tokens be sufficient for most applications?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F3Sc2vtrBCa"
      },
      "outputs": [],
      "source": [
        "def visualize_top_token_distribution(count_dict, num_tokens_to_plot):\n",
        "  \"\"\"\n",
        "  Display a barplot of counts of top <num_tokens_to_plot> tokens in the <count_dict>\n",
        "  \"\"\"\n",
        "  df = pd.DataFrame(data={\"token\": [key for key, _ in count_dict.items()], \"count\": [value for _, value in count_dict.items()]}).sort_values(\"count\", ascending=False)\n",
        "  df[:num_tokens_to_plot].plot(x = \"token\", y = \"count\", kind=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "FFGiXJuQrfHw",
        "outputId": "1b660b61-4042-4ec1-86b3-880a5499976c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_top_token_distribution(student_created_count_dict, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Bzx51_xpskwS",
        "outputId": "972e8d0f-1c6d-4402-d48d-efe5ce461709"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_top_token_distribution(student_created_count_dict, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "3n6QenP-smAd",
        "outputId": "29375581-e5fa-431c-f342-cfade1c8921f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "visualize_top_token_distribution(student_created_count_dict, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4woSRLSt6bt"
      },
      "source": [
        "### Q2.c.b [2 points] Take a look at the top 10 tokens in the plot above, do you think the embeddings based on those tokens will be informative for our task?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZCCCcILuG5N"
      },
      "source": [
        "* The distribution of token counts is a relatively heavy (left) tailed distribution. Since token counts decrease drastically, using the top 30 would be sufficient for most applications.\n",
        "\n",
        "* Embeddings based on the top 10 tokens will not be informative to detecting spam in text messages, because most texts will contain these tokens whether or not they are spam. As a result, we gain no new information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx96W-8PtrbV"
      },
      "source": [
        "## Q2.d [ 13 points ] Vocabulary selection and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKCpZXNCH5do"
      },
      "outputs": [],
      "source": [
        "# NOTHING TO DO HERE, JUST SOME CONVENIENCE FUNCTIONS FOR THE FUTURE\n",
        "def index_to_token(index:int, vocabulary:dict) -> str:\n",
        "  \"\"\"\n",
        "  Given an index in the vocabulary, and the vocabulary dict with tokens as keys, and indices as values, returns the token that maps to the given index\n",
        "  \"\"\"\n",
        "  if index > len(vocabulary):\n",
        "    raise ValueError(f\"There is no index {index} in the vocabulary\")\n",
        "  inv_vocabulary = {v: k for k, v in vocabulary.items()}\n",
        "  return inv_vocabulary[index]\n",
        "\n",
        "def token_to_index(token:str, vocabulary:dict) -> int:\n",
        "  \"\"\"\n",
        "  Given a token, return the index of that token in the vocabulary\n",
        "  \"\"\"\n",
        "  index = vocabulary.get(token)\n",
        "  if index is None:\n",
        "    raise ValueError(f\"Token: {token} is not in the vocabulary\")\n",
        "  return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5GFTnNtJhgV"
      },
      "outputs": [],
      "source": [
        "## NOTHING TO DO HERE\n",
        "\n",
        "# BoW with our vocab\n",
        "vectorizer_ours = CountVectorizer(max_features=500, tokenizer=tokenize, vocabulary=student_created_vocab) # Automatic BoW embeddings using your vocab\n",
        "vectorized_data_ours = vectorizer_ours.fit_transform(X_train) # Embedded data\n",
        "\n",
        "# Bow with an auto vocab\n",
        "vectorizer_auto = CountVectorizer(max_features=500) # Automatic BoW embeddings and automatic vocab\n",
        "vectorized_data_auto = vectorizer_auto.fit_transform(X_train) # Embedded data\n",
        "VOCAB = vectorizer_auto.vocabulary_ # For convenience\n",
        "\n",
        "# binary BoW\n",
        "vectorizer_bbow = CountVectorizer(max_features=500, binary=True, vocabulary=VOCAB) # Automatic binary BoW embeddings using the automatically generated vocab above\n",
        "vectorized_data_bbow = vectorizer_bbow.fit_transform(X_train) # Embedded data\n",
        "\n",
        "# TFIDF\n",
        "tfidf_transformer = TfidfTransformer(smooth_idf=False) # TF-IDF transformer for BoW embeddings\n",
        "vectorized_data_tfidf_auto = tfidf_transformer.fit_transform(vectorized_data_auto) # Embedded data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQFvomo9urR3"
      },
      "source": [
        "### Q2.d.a [ 2 points ] Implement the function `vocabulary_diff` below. It should return a list of tokens that are in `vocab_1` but not in `vocab_2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-CScQ3tKGPU",
        "outputId": "279186fd-67b6-4915-a3ec-4400732907f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'family': 482, 'food': 484, 'juz': 489}\n",
            "{'wen': 461, 'weekly': 459, 'wife': 471}\n"
          ]
        }
      ],
      "source": [
        "# Get the differences between our vocabulary and the automatically generated one\n",
        "\n",
        "def vocabulary_diff(vocab_1:dict, vocab_2:dict) -> List[str]:\n",
        "  \"\"\"\n",
        "  Given 2 vocabularies, returns all the tokens that are present in vocab_1 but not in vocab_2\n",
        "  \"\"\"\n",
        "  vocab_diff = {}\n",
        "\n",
        "  for key in vocab_1:\n",
        "    if key not in vocab_2:\n",
        "      vocab_diff[key] = vocab_1[key]\n",
        "  return vocab_diff\n",
        "\n",
        "\n",
        "print(vocabulary_diff(student_created_vocab,VOCAB))\n",
        "print(vocabulary_diff(VOCAB, student_created_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3gDDBttvyVW"
      },
      "source": [
        "###  Q2.d.b [3 points] Based on the differences between the two vocabularies, which do you think will represent our datapoints better? Why? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSDcv9SYwGJj"
      },
      "source": [
        "All token counts in VOCAB are lower than in student_created_vocab, so we should take the one that contains more popular tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDa_SZbdN1tA"
      },
      "outputs": [],
      "source": [
        "# Some convenience constants\n",
        "DOCUMENT_COUNTS = np.bincount(vectorized_data_bbow.indices, minlength=vectorized_data_bbow.shape[1])\n",
        "NUM_DATAPOINTS = len(X_train)\n",
        "VOCAB = vectorizer_auto.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvRheDH8w7lF"
      },
      "source": [
        "### Q2.d.c [3 points] Implement the `idf` function below which returns the inverse document frequency of a given word as defined by:\n",
        "\n",
        "$$ IDF(w_j) = log(\\frac{N}{N_j}) + 1 $$\n",
        "\n",
        "where:\n",
        "\n",
        "* $N$ is the number of datapoints \n",
        "\n",
        "* $N_j$ is the number of occurences of word $w_j$ in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-dlIRAPPzSE"
      },
      "outputs": [],
      "source": [
        "def idf(word:str, document_count:np.ndarray=DOCUMENT_COUNTS, num_datapoints:int=NUM_DATAPOINTS) -> float:\n",
        "  \"\"\"\n",
        "  returns the inverse document frequency of a particular word, based on the IDF definition of\n",
        "\n",
        "  IDF(w_j) = log(N / N_j) + 1\n",
        "\n",
        "  \"\"\"\n",
        "  N = num_datapoints\n",
        "  idx = token_to_index(word, VOCAB)\n",
        "  N_j = np.sum(DOCUMENT_COUNTS[idx])\n",
        "  print(\"N: \", N, \"N_j: \", N_j)\n",
        "  return np.log(N / N_j) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wEYAGnnQi97",
        "outputId": "644f4ab1-7eaa-4329-9487-751d06084cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "word: head\n",
            "N:  3901 N_j:  17\n",
            "your idf: 6.4357748654504405\n",
            "calculated idf: 6.4357748654504405\n",
            "N:  3901 N_j:  17\n",
            "word: ah\n",
            "N:  3901 N_j:  21\n",
            "your idf: 6.224465771783233\n",
            "calculated idf: 6.224465771783233\n",
            "N:  3901 N_j:  21\n",
            "word: customer\n",
            "N:  3901 N_j:  35\n",
            "your idf: 5.713640148017243\n",
            "calculated idf: 5.713640148017243\n",
            "N:  3901 N_j:  35\n",
            "word: dont\n",
            "N:  3901 N_j:  98\n",
            "your idf: 4.684020730836085\n",
            "calculated idf: 4.684020730836085\n",
            "N:  3901 N_j:  98\n",
            "word: where\n",
            "N:  3901 N_j:  82\n",
            "your idf: 4.862268962242403\n",
            "calculated idf: 4.862268962242403\n",
            "N:  3901 N_j:  82\n",
            "word: it\n",
            "N:  3901 N_j:  423\n",
            "your idf: 3.2216160304603783\n",
            "calculated idf: 3.2216160304603783\n",
            "N:  3901 N_j:  423\n",
            "word: po\n",
            "N:  3901 N_j:  24\n",
            "your idf: 6.0909343791587105\n",
            "calculated idf: 6.0909343791587105\n",
            "N:  3901 N_j:  24\n",
            "word: weekend\n",
            "N:  3901 N_j:  22\n",
            "your idf: 6.177945756148341\n",
            "calculated idf: 6.177945756148341\n",
            "N:  3901 N_j:  22\n",
            "word: co\n",
            "N:  3901 N_j:  39\n",
            "your idf: 5.60542656337701\n",
            "calculated idf: 5.60542656337701\n",
            "N:  3901 N_j:  39\n",
            "word: sms\n",
            "N:  3901 N_j:  36\n",
            "your idf: 5.685469271050547\n",
            "calculated idf: 5.685469271050547\n",
            "N:  3901 N_j:  36\n",
            "word: could\n",
            "N:  3901 N_j:  34\n",
            "your idf: 5.742627684890495\n",
            "calculated idf: 5.742627684890495\n",
            "N:  3901 N_j:  34\n",
            "word: service\n",
            "N:  3901 N_j:  40\n",
            "your idf: 5.58010875539272\n",
            "calculated idf: 5.58010875539272\n",
            "N:  3901 N_j:  40\n",
            "word: forgot\n",
            "N:  3901 N_j:  23\n",
            "your idf: 6.133493993577507\n",
            "calculated idf: 6.133493993577507\n",
            "N:  3901 N_j:  23\n",
            "word: easy\n",
            "N:  3901 N_j:  20\n",
            "your idf: 6.273255935952665\n",
            "calculated idf: 6.273255935952665\n",
            "N:  3901 N_j:  20\n",
            "word: first\n",
            "N:  3901 N_j:  41\n",
            "your idf: 5.555416142802349\n",
            "calculated idf: 5.555416142802349\n",
            "N:  3901 N_j:  41\n"
          ]
        }
      ],
      "source": [
        "for index in np.random.randint(0,500, size=15).tolist():\n",
        "  print(f\"word: {index_to_token(index, VOCAB)}\")\n",
        "  print(f\"your idf: {idf(index_to_token(index, VOCAB))}\")\n",
        "  print(f\"calculated idf: {tfidf_transformer.idf_[index]}\")\n",
        "  assert np.isclose(tfidf_transformer.idf_[index], idf(index_to_token(index, VOCAB)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIYmBJfkxg50"
      },
      "source": [
        "### Q2.d.d [2 points] Implement a binary Bag of Words embedding function that takes in a list of token and a vocab, and returns a numpy array corresponding to the embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvtjwrUyS0lT"
      },
      "outputs": [],
      "source": [
        "def binary_BoW_embedder(list_of_tokens:List[str], vocab:dict) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  Creates a binary Bag of Words embedding of a datapoint represented as a list of tokens, using the vocab\n",
        "  \"\"\"\n",
        "  # Hint: you may want to start with np.zeros()\n",
        "  embedding = np.zeros(len(vocab))\n",
        "  for i in range(len(list_of_tokens)):\n",
        "    embedding[token_to_index(list_of_tokens[i], vocab)] = 1\n",
        "\n",
        "  return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5kCOIlVUMrM",
        "outputId": "70518a31-2b76-4c6c-9d09-e2b5b3c3eaeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text: ['or', 'maybe', 'really', 'yeah', 'time', 'nothing', 'stuff', 'hello', 'wait', 'morning']\n",
            "your embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "calculated embedding: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n",
            "Success!\n",
            "text: ['getting', 'weekly', 'over', 'aight', 'make', 'like', 'receive', 'beautiful', 'wish', 'birthday']\n",
            "Success!\n",
            "text: ['got', 'with', 'he', 'were', 'missed', 'hear', 'wake', 'guess', 'wake', 'bed']\n",
            "Success!\n",
            "text: ['shit', 'best', 'looking', 'per', 'easy', 'worry', 'online', 'enjoy', 'ah', 'plus']\n",
            "Success!\n",
            "text: ['going', 'money', 'sweet', 'code', 'pain', 'about', 'long', 'might', 'remember', 'before']\n",
            "Success!\n",
            "text: ['stuff', 're', 'com', 'show', 'wait', 'watching', 'trying', 'messages', 'txt', 'apply']\n",
            "Success!\n",
            "text: ['how', 'care', 'tomorrow', 'because', 'service', 'sweet', '10', 'talk', 'being', 'dat']\n",
            "Success!\n",
            "text: ['means', 'orange', 'without', 'heart', 'there', 'join', 'babe', 'girl', 'hope', 'wake']\n",
            "Success!\n",
            "text: ['world', 'miss', 'said', 'on', 'missed', 'way', 'wen', 'it', 'mail', 'hear']\n",
            "Success!\n",
            "text: ['number', 'into', 'if', 'line', 'quite', 'show', 'before', 'much', 'though', 'job']\n",
            "Success!\n",
            "text: ['mail', 'he', 'speak', 'year', 'attempt', 'fuck', 'abt', 'oh', 'boy', 'receive']\n",
            "Success!\n",
            "text: ['please', '1st', 'really', 'dunno', 'yeah', 'enough', 'wife', 'bored', 'evening', 'your']\n",
            "Success!\n",
            "text: ['care', 'text', 'give', 'told', 'nice', 'sorry', 'meet', 'xxx', 'left', 'attempt']\n",
            "Success!\n",
            "text: ['amp', 'enjoy', 'home', 'pls', 'mins', 'today', 'anything', 'be', 'this', 'book']\n",
            "Success!\n",
            "text: ['its', 'not', 'cost', 'gt', 'service', 'is', 'wish', 'apply', 'wanna', 'late']\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "for test_num in range(15):\n",
        "  sample_token_indices = np.random.randint(0,500, size=10)\n",
        "  input_text = [index_to_token(index, VOCAB) for index in sample_token_indices]\n",
        "  input_text_as_str = \" \".join(input_text)\n",
        "  print(f\"text: {input_text}\")\n",
        "  if test_num == 0:\n",
        "    print(f\"your embedding: {binary_BoW_embedder(input_text, VOCAB)}\")\n",
        "    print(f\"calculated embedding: {vectorizer_bbow.transform([input_text_as_str]).toarray()}\")\n",
        "  assert np.isclose(binary_BoW_embedder(input_text, VOCAB), vectorizer_bbow.transform([input_text_as_str]).toarray()).all()\n",
        "  print(\"Success!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QvHSEz2xzAC"
      },
      "source": [
        "### Q2.d.e [2 points] Implement a Bag of Words embedding function that takes in a list of token and a vocab, and returns a numpy array corresponding to the embedding vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnWQOaXKaczA"
      },
      "outputs": [],
      "source": [
        "def BoW_embedder(list_of_tokens, vocab):\n",
        "  \"\"\"\n",
        "  Creates a binary Bag of Words embedding of a datapoint represented as a list of tokens, using the vocab\n",
        "  \"\"\"\n",
        "  # Hint: You may want to start with np.zeros()\n",
        "  embedding = np.zeros(len(vocab))\n",
        "  for i in range(len(list_of_tokens)):\n",
        "    embedding[token_to_index(list_of_tokens[i], vocab)] += 1\n",
        "\n",
        "  return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH4YTsgghcqE",
        "outputId": "c1ce7b51-610c-49b5-93d0-8e7024f25f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text: ['hours', 'hope', 'holiday', 'hours', 'home', 'hope', 'holiday', 'home', 'home', 'hour']\n",
            "your embedding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 2. 3. 2. 1. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "calculated embedding: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 2 1 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Success!\n",
            "text: ['hours', 'hope', 'holiday', 'hour', 'hours', 'hour', 'hours', 'hours', 'hope', 'hours']\n",
            "Success!\n",
            "text: ['hour', 'hours', 'hope', 'hope', 'hour', 'home', 'home', 'hours', 'holiday', 'hours']\n",
            "Success!\n",
            "text: ['hour', 'hour', 'hour', 'hour', 'hour', 'hope', 'home', 'hour', 'holiday', 'holiday']\n",
            "Success!\n",
            "text: ['holiday', 'holiday', 'hope', 'holiday', 'hour', 'hours', 'holiday', 'hope', 'hope', 'holiday']\n",
            "Success!\n",
            "text: ['hours', 'holiday', 'hope', 'home', 'hour', 'hope', 'holiday', 'hour', 'holiday', 'holiday']\n",
            "Success!\n",
            "text: ['home', 'hour', 'hour', 'home', 'hope', 'holiday', 'hours', 'holiday', 'holiday', 'hope']\n",
            "Success!\n",
            "text: ['holiday', 'home', 'home', 'hour', 'hours', 'holiday', 'holiday', 'hope', 'home', 'hours']\n",
            "Success!\n",
            "text: ['hour', 'home', 'hour', 'hope', 'hope', 'holiday', 'hours', 'hour', 'home', 'hope']\n",
            "Success!\n",
            "text: ['holiday', 'holiday', 'hour', 'hope', 'hours', 'hope', 'hour', 'hour', 'hope', 'hour']\n",
            "Success!\n",
            "text: ['hope', 'home', 'hope', 'hope', 'hour', 'hour', 'holiday', 'holiday', 'home', 'holiday']\n",
            "Success!\n",
            "text: ['hope', 'hour', 'holiday', 'holiday', 'home', 'home', 'hope', 'hour', 'home', 'holiday']\n",
            "Success!\n",
            "text: ['hour', 'hour', 'holiday', 'home', 'holiday', 'hour', 'hours', 'hours', 'hope', 'holiday']\n",
            "Success!\n",
            "text: ['holiday', 'hope', 'hope', 'hope', 'hour', 'holiday', 'hour', 'hope', 'holiday', 'hour']\n",
            "Success!\n",
            "text: ['hour', 'hope', 'holiday', 'hope', 'holiday', 'hours', 'home', 'home', 'home', 'hope']\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "for test_num in range(15):\n",
        "  sample_token_indices = np.random.randint(199,204, size=10)\n",
        "  input_text = [index_to_token(index, VOCAB) for index in sample_token_indices]\n",
        "  input_text_as_str = \" \".join(input_text)\n",
        "  print(f\"text: {input_text}\")\n",
        "  if test_num == 0:\n",
        "    print(f\"your embedding: {BoW_embedder(input_text, VOCAB)}\")\n",
        "    print(f\"calculated embedding: {vectorizer_auto.transform([input_text_as_str]).toarray()}\")\n",
        "  assert np.isclose(BoW_embedder(input_text, VOCAB), vectorizer_auto.transform([input_text_as_str]).toarray()).all()\n",
        "  print(\"Success!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_2Ff_JaiJ8_"
      },
      "source": [
        "##Q2.e [11 points] Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xkV3-sphmKl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bkq8Wnm7jSCn"
      },
      "outputs": [],
      "source": [
        "logreg_auto = LogisticRegression(random_state=1).fit(vectorized_data_auto, y_train)\n",
        "logreg_bbow = LogisticRegression(random_state=1).fit(vectorized_data_bbow, y_train)\n",
        "logreg_tfidf = LogisticRegression(random_state=1).fit(vectorized_data_tfidf_auto, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x166D5jgzcXD"
      },
      "source": [
        "### Q2.e.a [3 points] Evaluation Metrics\n",
        "Below you can see a set of simple accuracy scores: \n",
        "\n",
        "https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
        "\n",
        "In what situation would accuracy be a good evaluation metric? In what situation it wouldn't? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rBmtzT6dlmKo",
        "outputId": "7b1d68f1-6e6c-4a5f-8d46-c1d2fdd444f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " All 1s; accuracy on validation data: 0.1255980861244019\n",
            " All 0s; accuracy on validation data: 0.8744019138755981\n",
            " Logistic Regression on BoW embedding; accuracy on validation data: 0.9772727272727273\n",
            " Logistic Regression on binary BoW embedding; accuracy on validation data: 0.9808612440191388\n",
            " Logistic Regression on TF-IDF embedding; accuracy on validation data: 0.972488038277512\n"
          ]
        }
      ],
      "source": [
        "print(f\" All 1s; accuracy on validation data: {accuracy_score(y_val, np.ones_like(y_val))}\")\n",
        "\n",
        "print(f\" All 0s; accuracy on validation data: {accuracy_score(y_val, np.zeros_like(y_val))}\")\n",
        "\n",
        "print(f\" Logistic Regression on BoW embedding; accuracy on validation data: {accuracy_score(y_val, logreg_auto.predict(vectorizer_auto.transform(X_val)))}\")\n",
        "\n",
        "print(f\" Logistic Regression on binary BoW embedding; accuracy on validation data: {accuracy_score(y_val, logreg_bbow.predict(vectorizer_bbow.transform(X_val)))}\")\n",
        "\n",
        "print(f\" Logistic Regression on TF-IDF embedding; accuracy on validation data: {accuracy_score(y_val, logreg_tfidf.predict(tfidf_transformer.transform(vectorizer_auto.transform(X_val))))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3gZZYLy0f37"
      },
      "source": [
        "When comparing the Binary BoW, BoW, and TF-IDF models with each other, accuracy is a good evaluation metric, because it tells us how good each model is at guessing the classification.\n",
        "\n",
        "However, if we tried to compare the first two models (All 0s and All 1s) with each other, accuracy is not a good metric to use. In this case, all it represents is the proportion of 0s (87%) and 1s (13%) in the sample set. If we were to say that All 0s is a better model because it has a higher accuracy, that is not true because both models intrinsically perform the same.\n",
        "\n",
        "Lastly, in the case of comparing one of the first two models (All 0s or All 1s) with one of the last three models, this metric doesn’t capture the whole picture. If we say that the All 0s model performed decently, only slightly worse than one of the 3 learning models, and so it is suitable, we would be incorrect, again because our sample data happened to include far more 0s than ones, not reflecting the true performance of the model. \n",
        "\n",
        "This is likely in part due to the fact that the vast majority of text messages in general are likely to not be spam, but the more data available, the better picture we get about the performance of the All 1s and All 0s models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OWMNrwD0hwR"
      },
      "source": [
        "### Q2.e.b [8 points] Answer the following in one-two sentences (2 points each)\n",
        "\n",
        "* What is the interpretation of coefficient $\\beta_j$ with $j > 1$ (so not the intercept) in the Logistic regression model fit on the binary BoW embeddings?\n",
        "\n",
        "* What is the interpretation of coefficient $\\beta_j$ with $j > 1$ (so not the intercept) in the Logistic regression model fit on the BoW embeddings?\n",
        "\n",
        "* If we were to include 1-st order interaction terms in our Logistic Regression model fit on binary BoW embeddings, what would be the interpretation of a coefficient for that interaction ?\n",
        "\n",
        "* Is the above different from fitting a Logistic Regression on a combination of unigrams and bigrams (1-grams, and 2-grams)? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB4UdDyj11C_"
      },
      "source": [
        "*   $\\beta_j$ is the probability of a message being spam given presence of the $j$th token\n",
        "*   $\\beta_j$ is the probability of a message being spam as above, with weight depending on the count of $j$th token\n",
        "*   The likliness of that interaction to affect the probabilty of a message being spam\n",
        "*   It is different because the length of the token accounts for phrases and mulitple worded terms which the above lacks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFZJTJ9msv_V"
      },
      "source": [
        "## Q2.f [4 points] Word Vectors\n",
        "\n",
        "Below we will be using a set of pre-trained word embeddings from the SpaCy library. For the purpose of the questions below, assume that they were trained\n",
        "using a Skip-Gram objective as described in lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vllrC6GmURD"
      },
      "outputs": [],
      "source": [
        "# This installs a full pipeline of tokenizer -> embedder with additional components.\n",
        "\n",
        "import spacy\n",
        "spacy_pipeline = spacy.load('en_core_web_md') # If this line produces an error,\n",
        "# you might need to re-start the runtime after running the first cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHMjDoj22TiQ"
      },
      "source": [
        "### Q2.f.a [2 points] Implement the function get_document_embedding_from_spacy below to return the document embedding as the average of all vector embeddings.\n",
        "\n",
        "You are not allowed to use `tokens.vector` in your functions, but you can check against it that your solution is accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt-s7xVZm_5t"
      },
      "outputs": [],
      "source": [
        "def get_document_embedding_from_spacy(text:str) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  returns the embedding vector representing the entire text by averaging the \n",
        "  word level embeddings.\n",
        "\n",
        "  !! DO NOT USE tokens.vector directly!! \n",
        "  \"\"\"\n",
        "  tokens = spacy_pipeline(text)\n",
        "\n",
        "  # Hint: you can iterate over each token in `tokens` and access the underlying vector with .vector\n",
        "  word_embedding = np.zeros((len(tokens), len(tokens[1].vector)))\n",
        "  for i in range(len(tokens)):\n",
        "    word_embedding[i] = tokens[i].vector\n",
        "  document_embedding = np.mean(word_embedding, axis=0)\n",
        "\n",
        "  return document_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWf-PZXlp2Do",
        "outputId": "6810b115-4f38-46c0-d36e-e8ecc28865de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text: ['if', 'waiting', 'good', 'world', 'getting', 'bus', 'nice', 'thats', 'morning', 'on']\n",
            "your embedding: [ 5.77830383e-02  1.94456361e-01 -2.19950904e-01 -3.78643638e-02\n",
            "  9.56407272e-02  4.53359976e-02  8.85836272e-03 -1.45602456e-01\n",
            " -4.53000917e-02  2.39745457e+00 -2.43452186e-01 -1.15168364e-01\n",
            "  7.67919083e-02 -3.75229097e-02 -3.66774237e-01 -2.93011538e-02\n",
            " -1.47375274e-01  1.11763364e+00 -1.02154727e-01 -1.30321994e-02\n",
            " -3.26862729e-02  1.12621544e-01 -8.88800011e-03 -4.74057275e-02\n",
            "  5.76359115e-02 -2.09286190e-02 -2.14628641e-02 -1.40164999e-01\n",
            "  1.13103100e-01 -4.19531810e-02 -1.00099800e-01 -1.27693551e-01\n",
            " -6.14572579e-03  2.54744724e-02  8.97536383e-02  3.00560014e-02\n",
            "  7.57170917e-02  6.76214556e-02 -1.65086003e-01 -7.52437719e-02\n",
            "  1.71010007e-02 -2.83627290e-02 -8.08163607e-02  5.34527268e-02\n",
            "  2.79981866e-02  1.70090825e-01 -1.20148744e-01 -4.45693623e-02\n",
            " -1.18348817e-01 -6.59102186e-02 -1.07713271e-01  7.12039999e-02\n",
            "  1.02204530e-02  1.63156184e-01  3.67557429e-02  4.25189082e-02\n",
            " -7.49495456e-02 -7.51049993e-02 -3.92942727e-02 -7.31116339e-02\n",
            " -7.58016377e-02 -1.53665022e-01 -7.58426366e-02  1.45814546e-01\n",
            "  1.39052546e-01 -1.99691843e-02  3.19267809e-02  2.16017455e-01\n",
            "  1.60258170e-02  2.11662996e-01  1.29430650e-01  1.45465434e-02\n",
            "  2.75215911e-01 -3.38761796e-02  2.39774585e-02  1.34591834e-02\n",
            "  8.93220564e-02 -4.04253617e-02 -1.21790093e-01  2.81314634e-01\n",
            "  1.71319453e-01  9.96569991e-02 -6.07244570e-02  7.92801041e-03\n",
            "  7.88530924e-02 -5.62324569e-02  2.09131205e-01 -1.77664911e-01\n",
            "  1.87250000e-01  5.21639078e-02 -1.16070046e-01  1.21415992e-01\n",
            " -1.88078456e-01 -1.19548363e-01  9.60018171e-02 -4.38139101e-02\n",
            "  2.32090987e-03 -1.32953096e-01  8.41478684e-02  1.85054868e-01\n",
            " -8.41945647e-03 -2.99953635e-02  7.55881857e-03 -9.90392821e-02\n",
            "  7.50173542e-02 -5.58121362e-01  1.22538273e-01 -1.34616538e-02\n",
            "  3.80059107e-02  4.47868190e-02  4.05188171e-02 -2.27690273e-01\n",
            "  1.86875822e-01  5.14365462e-02  1.93801818e-01 -3.64411829e-02\n",
            " -1.44557304e-02 -5.25446368e-02  2.81055429e-02  1.81131830e-02\n",
            "  1.36125726e-01 -2.71609974e-02  1.64977529e-03 -8.94663357e-02\n",
            " -7.60962826e-02  9.75233635e-02 -8.70600216e-03 -1.89308675e-01\n",
            " -2.01377303e-02 -1.95053627e-01  8.55110918e-02 -6.78581824e-02\n",
            "  6.33580878e-02 -1.04209998e-01  8.33785458e-03 -8.84336335e-03\n",
            "  7.29555723e-02  3.47474566e-02 -4.32326377e-02 -3.76250590e-02\n",
            " -1.72876635e+00 -3.99908796e-03  2.39697632e-01 -9.18779987e-02\n",
            " -2.08243653e-02 -1.48535001e-01 -1.85276190e-01 -3.39964571e-02\n",
            "  3.64831820e-02 -5.29532699e-02 -1.70573093e-01  1.33184637e-01\n",
            "  5.06642909e-02 -1.11329272e-01 -5.35878182e-02 -1.18754600e-01\n",
            "  2.14977285e-02  7.34829058e-02  6.99279992e-02 -1.67445567e-01\n",
            " -2.42386722e-01  6.83415442e-02  2.06939495e-02 -6.72362067e-04\n",
            "  1.20769572e-01 -1.90180818e-01  2.52816352e-02 -5.28243628e-02\n",
            "  2.73993820e-01  3.08701829e-02  6.67453627e-03 -3.34038164e-02\n",
            " -1.81572783e-03 -1.70713002e-01 -1.31287849e-02  9.71101001e-02\n",
            " -7.00697282e-02  1.47352445e-02 -9.59532622e-02  4.13172539e-02\n",
            " -4.61540886e-02 -1.29487818e-01 -1.83645816e-01 -6.30893277e-02\n",
            " -7.71036474e-02  7.90366700e-03  5.18749180e-03  8.91946395e-02\n",
            "  3.44340889e-02 -3.21366367e-02 -3.08750925e-02  4.77984551e-02\n",
            " -1.63953852e-01  3.89654596e-03 -4.24803638e-02  9.74003639e-02\n",
            "  5.23957265e-02 -8.01101859e-02 -8.79954537e-02  6.12446354e-02\n",
            " -3.98226346e-02 -3.16522717e-02 -7.91559111e-02 -1.51726338e-02\n",
            "  2.19831911e-01 -1.16004544e-02 -2.59729004e-02 -6.55533289e-02\n",
            "  7.10451585e-02  1.31500897e-02 -9.51937285e-02 -1.72458273e-01\n",
            " -5.34484555e-02 -1.76113458e-01 -6.88379173e-03  1.34982364e-01\n",
            " -1.33643908e-01 -1.31463995e-01 -1.90599090e-01  3.11936367e-02\n",
            " -9.91306359e-02 -8.06855845e-02 -7.12927280e-02  1.50225455e-01\n",
            "  4.54659992e-02 -6.76870907e-02  6.99320918e-03  1.03146364e-01\n",
            " -2.00237861e-02  1.05326636e-01  2.77101824e-02  4.09435905e-02\n",
            "  6.43917733e-02  8.79969985e-02  5.44019595e-02 -1.15093818e-01\n",
            " -3.51989100e-02 -1.92908089e-01 -1.69472910e-01  2.49583091e-01\n",
            "  1.08928909e-01  1.09352819e-01 -6.13416109e-02  1.68795908e-01\n",
            " -1.93802711e-02 -1.37902274e-01 -1.17174222e-01 -9.32242704e-02\n",
            " -9.72017441e-02  5.91333661e-02 -1.08551002e-01 -1.68897547e-01\n",
            " -1.18406986e-02  3.81493262e-03  2.55680458e-02  3.11935825e-01\n",
            "  5.55644095e-02 -1.61560275e-01 -4.84270887e-02  4.29910017e-02\n",
            "  1.38611002e-01  1.44780908e-01  2.61982300e-02  1.22238001e-01\n",
            "  1.61081816e-01 -8.24994540e-02 -2.62260909e-02  1.13906456e-01\n",
            "  2.47419064e-01  8.57679385e-02 -1.04208179e-02  1.13211813e-02\n",
            " -1.67034732e-01 -2.26015997e-01 -1.49370894e-02  1.76304965e-01\n",
            " -1.41990591e-03  2.01474016e-02  1.89876159e-01  3.07975372e-01\n",
            "  7.46171793e-02 -1.47969634e-01 -3.28390258e-02  8.42370373e-02\n",
            "  1.21962711e-02 -5.07738170e-02  1.59365455e-01 -7.19816383e-02\n",
            " -5.22093646e-02  8.15249986e-02 -1.55073906e-01 -1.05681819e-02\n",
            "  8.00332687e-02 -1.61067354e-01  1.61134278e-01 -4.52299111e-02\n",
            "  6.08492763e-02 -1.67997637e-01 -2.93040467e-02  1.32381367e-01]\n",
            "calculated embedding: [ 5.77830411e-02  1.94456354e-01 -2.19950899e-01 -3.78643535e-02\n",
            "  9.56407264e-02  4.53359969e-02  8.85836128e-03 -1.45602450e-01\n",
            " -4.53000925e-02  2.39745450e+00 -2.43452176e-01 -1.15168363e-01\n",
            "  7.67919049e-02 -3.75229083e-02 -3.66774261e-01 -2.93011479e-02\n",
            " -1.47375271e-01  1.11763370e+00 -1.02154732e-01 -1.30321989e-02\n",
            " -3.26862708e-02  1.12621538e-01 -8.88800062e-03 -4.74057309e-02\n",
            "  5.76359145e-02 -2.09286213e-02 -2.14628633e-02 -1.40165001e-01\n",
            "  1.13103099e-01 -4.19531800e-02 -1.00099802e-01 -1.27693549e-01\n",
            " -6.14572596e-03  2.54744720e-02  8.97536427e-02  3.00560016e-02\n",
            "  7.57170990e-02  6.76214546e-02 -1.65086001e-01 -7.52437711e-02\n",
            "  1.71010010e-02 -2.83627287e-02 -8.08163583e-02  5.34527265e-02\n",
            "  2.79981866e-02  1.70090809e-01 -1.20148748e-01 -4.45693620e-02\n",
            " -1.18348815e-01 -6.59102127e-02 -1.07713267e-01  7.12039992e-02\n",
            "  1.02204541e-02  1.63156196e-01  3.67557406e-02  4.25188988e-02\n",
            " -7.49495476e-02 -7.51049966e-02 -3.92942689e-02 -7.31116310e-02\n",
            " -7.58016407e-02 -1.53665036e-01 -7.58426413e-02  1.45814538e-01\n",
            "  1.39052555e-01 -1.99691840e-02  3.19267809e-02  2.16017440e-01\n",
            "  1.60258133e-02  2.11663008e-01  1.29430652e-01  1.45465434e-02\n",
            "  2.75215894e-01 -3.38761769e-02  2.39774603e-02  1.34591851e-02\n",
            "  8.93220603e-02 -4.04253602e-02 -1.21790081e-01  2.81314641e-01\n",
            "  1.71319470e-01  9.96569917e-02 -6.07244521e-02  7.92801008e-03\n",
            "  7.88530931e-02 -5.62324524e-02  2.09131196e-01 -1.77664891e-01\n",
            "  1.87249988e-01  5.21639027e-02 -1.16070040e-01  1.21415980e-01\n",
            " -1.88078448e-01 -1.19548365e-01  9.60018113e-02 -4.38139103e-02\n",
            "  2.32090964e-03 -1.32953092e-01  8.41478705e-02  1.85054868e-01\n",
            " -8.41945037e-03 -2.99953651e-02  7.55881984e-03 -9.90392864e-02\n",
            "  7.50173628e-02 -5.58121324e-01  1.22538276e-01 -1.34616550e-02\n",
            "  3.80059145e-02  4.47868183e-02  4.05188203e-02 -2.27690279e-01\n",
            "  1.86875820e-01  5.14365472e-02  1.93801820e-01 -3.64411809e-02\n",
            " -1.44557301e-02 -5.25446385e-02  2.81055402e-02  1.81131884e-02\n",
            "  1.36125743e-01 -2.71609947e-02  1.64977228e-03 -8.94663334e-02\n",
            " -7.60962889e-02  9.75233540e-02 -8.70600343e-03 -1.89308658e-01\n",
            " -2.01377291e-02 -1.95053622e-01  8.55110958e-02 -6.78581819e-02\n",
            "  6.33580908e-02 -1.04210012e-01  8.33785534e-03 -8.84336513e-03\n",
            "  7.29555786e-02  3.47474553e-02 -4.32326384e-02 -3.76250595e-02\n",
            " -1.72876632e+00 -3.99908703e-03  2.39697650e-01 -9.18780044e-02\n",
            " -2.08243653e-02 -1.48534998e-01 -1.85276210e-01 -3.39964591e-02\n",
            "  3.64831835e-02 -5.29532693e-02 -1.70573100e-01  1.33184642e-01\n",
            "  5.06642908e-02 -1.11329272e-01 -5.35878167e-02 -1.18754603e-01\n",
            "  2.14977264e-02  7.34829009e-02  6.99280053e-02 -1.67445555e-01\n",
            " -2.42386729e-01  6.83415532e-02  2.06939504e-02 -6.72362046e-04\n",
            "  1.20769568e-01 -1.90180823e-01  2.52816360e-02 -5.28243557e-02\n",
            "  2.73993820e-01  3.08701806e-02  6.67453604e-03 -3.34038176e-02\n",
            " -1.81572617e-03 -1.70713007e-01 -1.31287863e-02  9.71101001e-02\n",
            " -7.00697303e-02  1.47352424e-02 -9.59532708e-02  4.13172506e-02\n",
            " -4.61540855e-02 -1.29487813e-01 -1.83645815e-01 -6.30893409e-02\n",
            " -7.71036446e-02  7.90366810e-03  5.18748956e-03  8.91946331e-02\n",
            "  3.44340913e-02 -3.21366377e-02 -3.08750924e-02  4.77984548e-02\n",
            " -1.63953856e-01  3.89653980e-03 -4.24803644e-02  9.74003598e-02\n",
            "  5.23957275e-02 -8.01101923e-02 -8.79954547e-02  6.12446330e-02\n",
            " -3.98226343e-02 -3.16522792e-02 -7.91558996e-02 -1.51726389e-02\n",
            "  2.19831899e-01 -1.16004497e-02 -2.59728972e-02 -6.55533299e-02\n",
            "  7.10451603e-02  1.31500848e-02 -9.51937363e-02 -1.72458276e-01\n",
            " -5.34484498e-02 -1.76113456e-01 -6.88379258e-03  1.34982362e-01\n",
            " -1.33643910e-01 -1.31464005e-01 -1.90599099e-01  3.11936382e-02\n",
            " -9.91306379e-02 -8.06855857e-02 -7.12927282e-02  1.50225461e-01\n",
            "  4.54660021e-02 -6.76870942e-02  6.99320715e-03  1.03146367e-01\n",
            " -2.00237855e-02  1.05326630e-01  2.77101826e-02  4.09435891e-02\n",
            "  6.43917769e-02  8.79969969e-02  5.44019565e-02 -1.15093820e-01\n",
            " -3.51989083e-02 -1.92908093e-01 -1.69472903e-01  2.49583095e-01\n",
            "  1.08928911e-01  1.09352827e-01 -6.13416098e-02  1.68795913e-01\n",
            " -1.93802733e-02 -1.37902275e-01 -1.17174223e-01 -9.32242796e-02\n",
            " -9.72017497e-02  5.91333658e-02 -1.08551003e-01 -1.68897539e-01\n",
            " -1.18406983e-02  3.81493033e-03  2.55680457e-02  3.11935812e-01\n",
            "  5.55644147e-02 -1.61560282e-01 -4.84270900e-02  4.29910049e-02\n",
            "  1.38611004e-01  1.44780919e-01  2.61982325e-02  1.22238010e-01\n",
            "  1.61081806e-01 -8.24994519e-02 -2.62260921e-02  1.13906451e-01\n",
            "  2.47419029e-01  8.57679397e-02 -1.04208142e-02  1.13211805e-02\n",
            " -1.67034730e-01 -2.26016000e-01 -1.49370879e-02  1.76304951e-01\n",
            " -1.41990290e-03  2.01474018e-02  1.89876169e-01  3.07975382e-01\n",
            "  7.46171772e-02 -1.47969633e-01 -3.28390263e-02  8.42370465e-02\n",
            "  1.21962661e-02 -5.07738143e-02  1.59365445e-01 -7.19816387e-02\n",
            " -5.22093661e-02  8.15249979e-02 -1.55073911e-01 -1.05681811e-02\n",
            "  8.00332725e-02 -1.61067352e-01  1.61134288e-01 -4.52299155e-02\n",
            "  6.08492754e-02 -1.67997643e-01 -2.93040462e-02  1.32381380e-01]\n",
            "Success!\n",
            "text: ['thing', 'still', 'text', 'enjoy', 'here', 'then', 'dun', 'anything', 'guy', 'weekly']\n",
            "Success!\n",
            "text: ['vouchers', 'sleep', 'who', 'some', 'aight', 'little', 'full', 'as', 'leave', 'shopping']\n",
            "Success!\n",
            "text: ['bed', 'use', 'messages', 'my', 'am', 'last', 'morning', 'never', 'cool', 'name']\n",
            "Success!\n",
            "text: ['show', 'wan', 'word', 'wat', 'part', 'on', 'find', '1000', 'apply', 'hello']\n",
            "Success!\n",
            "text: ['beautiful', 'actually', 'gt', 'just', 'full', 'without', 'back', 'sms', '150ppm', 'cost']\n",
            "Success!\n",
            "text: ['speak', 'let', 'around', 'much', 'room', 'yo', 'ok', 'half', 'coming', 'cost']\n",
            "Success!\n",
            "text: ['he', 'word', 'dis', 'heart', 'make', 'while', 'tmr', 'why', 'getting', 'many']\n",
            "Success!\n",
            "text: ['pick', 'dun', 'after', 'music', 'xxx', 'know', 'being', 'big', 'pick', 'service']\n",
            "Success!\n",
            "text: ['gud', 'much', 'didnt', 'next', 'txt', 'ready', 'for', 'want', 'driving', 'friends']\n",
            "Success!\n",
            "text: ['xxx', 'stuff', 'win', 'mobile', 'da', 'to', 'than', 'offer', 'lot', 'guy']\n",
            "Success!\n",
            "text: ['ask', 'without', 'got', 'love', 'always', 'school', 'one', 'those', 'thk', 'able']\n",
            "Success!\n",
            "text: ['pain', 'tell', 'out', 'are', 'guaranteed', 'again', 'person', 'messages', 'years', 'them']\n",
            "Success!\n",
            "text: ['everything', 'weekly', 'sleep', 'why', 'face', 'com', 'say', 'phone', 'next', 'it']\n",
            "Success!\n",
            "text: ['walk', 'ready', 'bed', 'free', 'haven', 'bored', 'hear', 'dreams', 'first', 'over']\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "# TEST FOR THE get_document_embedding_from_spacy function\n",
        "for test_num in range(15):\n",
        "  sample_token_indices = np.random.randint(0,500, size=10)\n",
        "  input_text = [index_to_token(index, VOCAB) for index in sample_token_indices]\n",
        "  input_text_as_str = \" \".join(input_text)\n",
        "  print(f\"text: {input_text}\")\n",
        "  if test_num == 0:\n",
        "    print(f\"your embedding: {get_document_embedding_from_spacy(input_text_as_str)}\")\n",
        "    print(f\"calculated embedding: {spacy_pipeline(input_text_as_str).vector}\")\n",
        "  assert np.isclose(get_document_embedding_from_spacy(input_text_as_str), spacy_pipeline(input_text_as_str).vector).all()\n",
        "  print(\"Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsTeOHpY2g0w",
        "outputId": "022d267c-81f8-4466-9df9-72e410bf0e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Logistic Regression on Word2Vec embedding; accuracy on validation data: 0.9677033492822966\n"
          ]
        }
      ],
      "source": [
        "# This might take around 1 minute to run\n",
        "X_train_spacy = np.vstack([get_document_embedding_from_spacy(x) for x in X_train])\n",
        "X_valid_spacy = np.vstack([get_document_embedding_from_spacy(x) for x in X_val])\n",
        "logreg_w2v = LogisticRegression(random_state=1, max_iter=1000).fit(X_train_spacy, y_train)\n",
        "print(f\" Logistic Regression on Word2Vec embedding; accuracy on validation data: {accuracy_score(y_val , logreg_w2v.predict(X_valid_spacy))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUgPJT303570"
      },
      "source": [
        "### Q2.f.b [2 points] Implement the function get_document_embedding_from_spacy_alt below to return the document embedding based on the token vectors.\n",
        "\n",
        "Feel free to let your imagination run, or go with simplicity. Don't use the average as above. Feel free to play around and see what works and what doesn't."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PK2CpdcuOil"
      },
      "outputs": [],
      "source": [
        "def get_document_embedding_from_spacy_alt(text:str) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  returns the embedding vector representing the entire text by whatever means you\n",
        "  would like based on the token level embeddings\n",
        "  \"\"\"\n",
        "  tokens = spacy_pipeline(text)\n",
        "  \n",
        "  document_embedding = np.amax(tokens.vector, axis=0) # using the columnwise max\n",
        "\n",
        "  return document_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrgKFCLjp2ko"
      },
      "outputs": [],
      "source": [
        "# This might take around a 1 minute\n",
        "X_train_spacy_alt = np.vstack([get_document_embedding_from_spacy_alt(x) for x in X_train])\n",
        "X_valid_spacy_alt = np.vstack([get_document_embedding_from_spacy_alt(x) for x in X_val])\n",
        "logreg_w2v_alt = LogisticRegression(random_state=1, max_iter=1000).fit(X_train_spacy_alt, y_train)\n",
        "print(f\" Logistic Regression on Word2Vec alternative embedding; accuracy on validation data: {accuracy_score(y_val , logreg_w2v_alt.predict(X_valid_spacy_alt))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzxBMiHBvaum"
      },
      "source": [
        "## Combining Embeddings [Free]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMx3NlAquqMG"
      },
      "outputs": [],
      "source": [
        "X_train_combined = np.hstack((X_train_spacy, vectorized_data_auto.toarray()))\n",
        "X_val_combined = np.hstack((X_valid_spacy, vectorizer_auto.transform(X_val).toarray()))\n",
        "logreg_combined = LogisticRegression(random_state=1, max_iter=1000).fit(X_train_combined, y_train)\n",
        "print(f\" Logistic Regression on combined W2V and BoW embeddings; accuracy on validation data: {logreg_combined.score(X_val_combined, y_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN4fRAjfxioQ"
      },
      "source": [
        "##[2 points] Q2.g Transformer Model\n",
        "\n",
        "Below we will be using embeddings produced by a \"Transformer\" model (we will learn more about these in week 12/13), for the embedding of each token, it aims to incorporate not only the meaning of the token, but also the specific context in which it occurs here, with the context being a fixed window of size 512."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWudJJ2Qxhxn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-tiny-finetuned-sms-spam-detection\") # This model has been trained on this data\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/bert-tiny-finetuned-sms-spam-detection\", output_hidden_states = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F6WNlHq57yJ"
      },
      "source": [
        "### Q2.g.a [2 points] Finish the implementation of get_embedding_from_transformer to produce a document level embedding given some text. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u49GVcFtxsV4"
      },
      "outputs": [],
      "source": [
        "def get_embedding_from_transformer(text:str) -> np.ndarray:\n",
        "  \"\"\"\n",
        "  Returns an embedding from a transformer model produced by averaging the token level embeddings\n",
        "  \"\"\"\n",
        "  tokenized = tokenizer([text])\n",
        "  for key, value in tokenized.items():\n",
        "    tokenized[key] = torch.LongTensor(value)\n",
        "  with torch.no_grad():\n",
        "    token_embeddings = model.forward(**tokenized)[\"hidden_states\"][0].numpy()[0]\n",
        "  # print(token_embeddings.shape)\n",
        "  document_embedding = np.mean(token_embeddings, axis=0)\n",
        "  return document_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2zZOpJb6ZNt"
      },
      "outputs": [],
      "source": [
        "# JUST SOME TESTING THAT IT RUNS AND PRODUCES THE RIGHT SIZE\n",
        "for e in [get_embedding_from_transformer(x) for x in X_train[:3]]:\n",
        "  assert e.shape == (128,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ_EvOXAylxs"
      },
      "outputs": [],
      "source": [
        "# This might take around a 1 minute\n",
        "X_train_transformer = np.vstack([get_embedding_from_transformer(x) for x in X_train])\n",
        "X_valid_transformer = np.vstack([get_embedding_from_transformer(x) for x in X_val])\n",
        "logreg_transformer = LogisticRegression(random_state=1, max_iter=1000).fit(X_train_transformer, y_train)\n",
        "print(f\" Logistic Regression on Transformer embedding accuracy on validation: {logreg_transformer.score(X_valid_transformer, y_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLt2Q4iWfeP9"
      },
      "source": [
        "## Q2.h [3 points] Which spam detection method worked best? Why do you think that is? What are some considerations you would need to make to use this model in practice? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5LEwqxPpz_P"
      },
      "source": [
        "We say that the spam detection method that worked the best is the one with the highest accuracy. Thus, the best spam detection method based on our findings is the Logistic Regression on Transformer embedding. \n",
        "\n",
        "That is because it aims to incorporate not only the meaning of the token, but also the specific context in which it occurs.\n",
        "\n",
        "On the philosophy of validation and accuracy as metrics towards analyzing the performance of models in spam detection, we may sufficiently conclude that the foremost requirement is a substantial amount of sample data in both spam and non-spam cases."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MWyKRONCVFYD"
      ],
      "name": "414 Solo Assignment 3-2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "096cf2df2a6d4528abeb278a9052a2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286c0d606def4bef863dce56c054edf3",
            "placeholder": "​",
            "style": "IPY_MODEL_2e6a5649710f4bf8b2c070f1d3062ff9",
            "value": "100%"
          }
        },
        "1349f6db6f404b85bb78e86f5b55bff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0e7c008f8a4c01a2687786c953c987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286c0d606def4bef863dce56c054edf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a80b85e68ad4282ba783c797609f0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90e1adccc17d4be18d4b2acd45781920",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c14746adc894090ab69ed81222578d6",
            "value": 1
          }
        },
        "2e6a5649710f4bf8b2c070f1d3062ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47ecf0729e0e4254b9e8ee8799046881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_096cf2df2a6d4528abeb278a9052a2e3",
              "IPY_MODEL_2a80b85e68ad4282ba783c797609f0b7",
              "IPY_MODEL_f2e46b810c2f418fb03425f4d340a1ff"
            ],
            "layout": "IPY_MODEL_efe8416bb61f48f2a2ea5a9577eaf9e5"
          }
        },
        "6c14746adc894090ab69ed81222578d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90e1adccc17d4be18d4b2acd45781920": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe8416bb61f48f2a2ea5a9577eaf9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e46b810c2f418fb03425f4d340a1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c0e7c008f8a4c01a2687786c953c987",
            "placeholder": "​",
            "style": "IPY_MODEL_1349f6db6f404b85bb78e86f5b55bff9",
            "value": " 1/1 [00:00&lt;00:00, 27.96it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}